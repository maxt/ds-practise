{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIvhwE4zxX0s",
        "outputId": "bca0a72d-5557-4e0b-8557-4667ef1b9fc6"
      },
      "outputs": [],
      "source": [
        "#Установка нужных пакетов\n",
        "#pip install --upgrade nltk gensim bokeh umap-learn\n",
        "\n",
        "import itertools\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import umap\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF9WPCtfxZR9",
        "outputId": "7442ba42-a17b-478b-ae9b-e5f1784d7323"
      },
      "outputs": [],
      "source": [
        "# выгружаем датасет:\n",
        "#wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt -nc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MaFpN9pvxtNg",
        "outputId": "d7aa8e42-ce7d-4f8e-ac33-4166a640c220"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'What are some ways to overcome a fast food addiction?\\n'"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = list(open(\"./quora.txt\", encoding=\"utf-8\"))\n",
        "data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvXRbOKGx0l_",
        "outputId": "f265a2aa-fc44-4763-bc87-fe05ee0a7203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['What', 'are', 'some', 'ways', 'to', 'overcome', 'a', 'fast', 'food', 'addiction', '?']\n"
          ]
        }
      ],
      "source": [
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "print(tokenizer.tokenize(data[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovkxi_QOySCl"
      },
      "source": [
        "#Задание 1: Перевести все слова в нижний регистр (NLTK) из data и добавьте как лист токенов в листе data_tok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "EK7uvHi6zeWY"
      },
      "outputs": [],
      "source": [
        "data_tok = list()\n",
        "for a in data:\n",
        "    current_token = tokenizer.tokenize(a)\n",
        "    row = list()\n",
        "    for b in current_token:\n",
        "        row.append(b.lower())\n",
        "    data_tok.append(row)\n",
        "\n",
        "#checking\n",
        "\n",
        "assert all(isinstance(row, (list, tuple)) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
        "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
        "assert all(map(lambda l: not is_latin(l) or l.islower(), map(' '.join, data_tok))), \"please make sure to lowercase the data\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtKeoLCYzY4j"
      },
      "source": [
        "###Задание 2: Подсчитайте топ10 самых популярных лем в рамках data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /Users/max/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /Users/max/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "ps = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "a_BxzSv9yR0w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocabulary size: 87820\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('?', 552413),\n",
              " ('the', 252068),\n",
              " ('what', 214798),\n",
              " ('is', 185392),\n",
              " ('a', 155726),\n",
              " ('i', 149735),\n",
              " ('to', 141788),\n",
              " ('in', 139787),\n",
              " ('how', 135687),\n",
              " ('of', 112001),\n",
              " ('do', 104282),\n",
              " ('are', 98049),\n",
              " ('and', 89442),\n",
              " ('for', 74801),\n",
              " ('can', 73702),\n",
              " (',', 72487),\n",
              " ('you', 60753),\n",
              " (\"'\", 57241),\n",
              " ('why', 56211),\n",
              " ('.', 52961),\n",
              " ('it', 52425),\n",
              " ('my', 45184),\n",
              " ('best', 40992),\n",
              " ('does', 39619),\n",
              " ('on', 38005),\n",
              " ('or', 33240),\n",
              " ('s', 31078),\n",
              " ('if', 30446),\n",
              " ('have', 30277),\n",
              " ('be', 29521),\n",
              " ('with', 29149),\n",
              " ('which', 29045),\n",
              " ('that', 28454),\n",
              " ('an', 28022),\n",
              " ('some', 27382),\n",
              " ('-', 26910),\n",
              " ('should', 26529),\n",
              " ('get', 25827),\n",
              " ('from', 25273),\n",
              " ('\"', 21714),\n",
              " ('your', 20585),\n",
              " ('(', 19478),\n",
              " ('like', 19049),\n",
              " ('when', 18923),\n",
              " ('at', 18343),\n",
              " ('india', 18334),\n",
              " ('good', 17685),\n",
              " ('who', 17517),\n",
              " ('there', 17170),\n",
              " ('will', 16860),\n",
              " ('as', 16787),\n",
              " ('t', 16785),\n",
              " ('people', 16398),\n",
              " ('would', 16389),\n",
              " ('not', 15325),\n",
              " ('/', 15038),\n",
              " ('about', 14416),\n",
              " ('between', 13959),\n",
              " ('one', 13793),\n",
              " ('any', 12646),\n",
              " ('we', 12617),\n",
              " ('me', 12521),\n",
              " ('where', 12430),\n",
              " ('most', 12416),\n",
              " ('did', 12137),\n",
              " ('was', 11785),\n",
              " ('by', 11756),\n",
              " ('make', 11437),\n",
              " ('so', 11399),\n",
              " ('they', 11119),\n",
              " (')', 11087),\n",
              " ('this', 11055),\n",
              " ('am', 10529),\n",
              " ('after', 10275),\n",
              " ('way', 10271),\n",
              " ('has', 9530),\n",
              " ('use', 9483),\n",
              " (':', 9399),\n",
              " ('much', 9391),\n",
              " ('time', 9362),\n",
              " ('life', 9283),\n",
              " ('difference', 9275),\n",
              " ('work', 8710),\n",
              " ('their', 8587),\n",
              " ('know', 8346),\n",
              " ('many', 8143),\n",
              " ('but', 7987),\n",
              " ('all', 7751),\n",
              " ('than', 7741),\n",
              " ('more', 7707),\n",
              " ('want', 7473),\n",
              " ('quora', 7469),\n",
              " ('someone', 7443),\n",
              " ('learn', 7265),\n",
              " ('find', 7147),\n",
              " ('other', 7111),\n",
              " ('think', 7099),\n",
              " ('new', 7018),\n",
              " ('better', 6823),\n",
              " ('2', 6729),\n",
              " ('job', 6693),\n",
              " ('indian', 6651),\n",
              " ('out', 6617),\n",
              " ('m', 6473),\n",
              " ('money', 6467),\n",
              " ('year', 6435),\n",
              " ('mean', 6383),\n",
              " ('become', 6350),\n",
              " ('he', 6260),\n",
              " ('ever', 6215),\n",
              " ('world', 6212),\n",
              " ('up', 6207),\n",
              " ('start', 6154),\n",
              " ('without', 6094),\n",
              " ('us', 6036),\n",
              " ('1', 5999),\n",
              " ('first', 5998),\n",
              " ('take', 5969),\n",
              " ('don', 5825),\n",
              " ('feel', 5764),\n",
              " ('into', 5709),\n",
              " (')?', 5540),\n",
              " ('go', 5424),\n",
              " ('online', 5272),\n",
              " ('used', 5156),\n",
              " ('engineering', 5119),\n",
              " ('love', 5063),\n",
              " ('day', 4964),\n",
              " ('person', 4951),\n",
              " ('could', 4866),\n",
              " ('3', 4847),\n",
              " ('possible', 4830),\n",
              " ('were', 4829),\n",
              " ('her', 4801),\n",
              " ('buy', 4749),\n",
              " ('things', 4743),\n",
              " ('being', 4678),\n",
              " ('his', 4656),\n",
              " ('business', 4655),\n",
              " ('need', 4616),\n",
              " ('old', 4547),\n",
              " ('them', 4516),\n",
              " ('using', 4515),\n",
              " ('5', 4513),\n",
              " ('girl', 4481),\n",
              " ('trump', 4479),\n",
              " ('really', 4462),\n",
              " ('\"?', 4376),\n",
              " ('years', 4359),\n",
              " ('long', 4351),\n",
              " ('google', 4245),\n",
              " ('different', 4223),\n",
              " ('phone', 4124),\n",
              " ('company', 4116),\n",
              " ('no', 4083),\n",
              " ('only', 4030),\n",
              " ('now', 4020),\n",
              " ('been', 4013),\n",
              " ('just', 3941),\n",
              " ('2016', 3905),\n",
              " ('app', 3899),\n",
              " ('free', 3843),\n",
              " ('college', 3830),\n",
              " ('facebook', 3823),\n",
              " ('she', 3778),\n",
              " ('number', 3764),\n",
              " ('books', 3736),\n",
              " ('movie', 3645),\n",
              " ('english', 3637),\n",
              " ('book', 3609),\n",
              " ('women', 3582),\n",
              " ('account', 3577),\n",
              " ('its', 3574),\n",
              " ('still', 3570),\n",
              " ('while', 3536),\n",
              " ('change', 3520),\n",
              " ('over', 3481),\n",
              " ('computer', 3475),\n",
              " ('ways', 3474),\n",
              " ('had', 3465),\n",
              " ('10', 3443),\n",
              " ('data', 3433),\n",
              " ('thing', 3424),\n",
              " ('see', 3415),\n",
              " ('country', 3410),\n",
              " ('examples', 3404),\n",
              " ('c', 3395),\n",
              " ('school', 3366),\n",
              " ('science', 3361),\n",
              " ('android', 3347),\n",
              " ('help', 3340),\n",
              " ('live', 3324),\n",
              " ('software', 3322),\n",
              " ('language', 3270),\n",
              " ('before', 3269),\n",
              " ('same', 3260),\n",
              " ('going', 3239),\n",
              " ('bad', 3230),\n",
              " ('sex', 3229),\n",
              " ('&', 3225),\n",
              " ('4', 3225),\n",
              " ('student', 3187),\n",
              " ('back', 3153),\n",
              " ('stop', 3132),\n",
              " ('university', 3121),\n",
              " ('made', 3119),\n",
              " ('math', 3092),\n",
              " ('happen', 3087),\n",
              " ('two', 3078),\n",
              " ('study', 3076),\n",
              " ('real', 3075),\n",
              " ('our', 3021),\n",
              " ('name', 3009),\n",
              " ('system', 2993),\n",
              " ('through', 2982),\n",
              " ('say', 2962),\n",
              " ('high', 2957),\n",
              " ('top', 2942),\n",
              " ('water', 2913),\n",
              " ('website', 2907),\n",
              " ('iphone', 2906),\n",
              " ('during', 2902),\n",
              " ('prepare', 2900),\n",
              " ('men', 2865),\n",
              " ('car', 2849),\n",
              " ('questions', 2838),\n",
              " ('black', 2830),\n",
              " ('important', 2821),\n",
              " ('companies', 2802),\n",
              " ('give', 2796),\n",
              " ('getting', 2795),\n",
              " ('read', 2793),\n",
              " ('anyone', 2788),\n",
              " ('learning', 2764),\n",
              " ('programming', 2736),\n",
              " ('card', 2730),\n",
              " ('war', 2718),\n",
              " ('b', 2656),\n",
              " ('exam', 2632),\n",
              " ('movies', 2598),\n",
              " ('right', 2597),\n",
              " ('then', 2597),\n",
              " ('even', 2582),\n",
              " ('mobile', 2579),\n",
              " ('him', 2560),\n",
              " ('china', 2552),\n",
              " ('cost', 2535),\n",
              " ('x', 2527),\n",
              " ('’', 2519),\n",
              " ('friend', 2502),\n",
              " ('working', 2484),\n",
              " ('president', 2479),\n",
              " ('donald', 2475),\n",
              " ('doing', 2474),\n",
              " ('under', 2463),\n",
              " ('non', 2457),\n",
              " ('question', 2427),\n",
              " ('6', 2422),\n",
              " ('come', 2420),\n",
              " ('own', 2410),\n",
              " ('career', 2393),\n",
              " ('+', 2390),\n",
              " ('experience', 2371),\n",
              " ('word', 2366),\n",
              " ('friends', 2366),\n",
              " ('bank', 2361),\n",
              " ('true', 2349),\n",
              " ('home', 2349),\n",
              " ('man', 2349),\n",
              " ('guy', 2342),\n",
              " ('web', 2337),\n",
              " ('doesn', 2337),\n",
              " ('usa', 2308),\n",
              " ('hair', 2307),\n",
              " ('video', 2305),\n",
              " ('look', 2299),\n",
              " ('having', 2296),\n",
              " ('social', 2287),\n",
              " ('off', 2284),\n",
              " ('tell', 2280),\n",
              " ('engineer', 2277),\n",
              " ('write', 2255),\n",
              " ('game', 2252),\n",
              " ('interview', 2251),\n",
              " ('earth', 2250),\n",
              " ('service', 2239),\n",
              " ('very', 2238),\n",
              " ('girls', 2231),\n",
              " ('government', 2227),\n",
              " ('weight', 2224),\n",
              " ('food', 2218),\n",
              " ('human', 2215),\n",
              " ('play', 2199),\n",
              " ('students', 2194),\n",
              " ('countries', 2193),\n",
              " ('place', 2176),\n",
              " ('ve', 2163),\n",
              " ('u', 2162),\n",
              " ('future', 2152),\n",
              " ('improve', 2136),\n",
              " ('class', 2134),\n",
              " ('tv', 2123),\n",
              " ('big', 2110),\n",
              " ('days', 2104),\n",
              " ('state', 2102),\n",
              " ('7', 2092),\n",
              " ('eat', 2084),\n",
              " ('com', 2083),\n",
              " ('done', 2080),\n",
              " ('happens', 2079),\n",
              " ('average', 2065),\n",
              " ('process', 2053),\n",
              " ('got', 2041),\n",
              " ('e', 2002),\n",
              " ('music', 1994),\n",
              " ('white', 1987),\n",
              " ('meaning', 1983),\n",
              " ('relationship', 1982),\n",
              " ('too', 1974),\n",
              " ('last', 1970),\n",
              " ('girlfriend', 1967),\n",
              " ('create', 1957),\n",
              " ('instagram', 1956),\n",
              " ('pay', 1952),\n",
              " ('history', 1952),\n",
              " ('every', 1948),\n",
              " ('windows', 1947),\n",
              " ('delhi', 1939),\n",
              " ('american', 1939),\n",
              " ('watch', 1931),\n",
              " ('body', 1930),\n",
              " ('tech', 1926),\n",
              " ('salary', 1919),\n",
              " ('safe', 1912),\n",
              " ('power', 1911),\n",
              " ('hard', 1908),\n",
              " ('laptop', 1906),\n",
              " ('ask', 1905),\n",
              " ('clinton', 1903),\n",
              " ('age', 1897),\n",
              " ('makes', 1875),\n",
              " ('energy', 1870),\n",
              " ('end', 1865),\n",
              " ('each', 1863),\n",
              " ('youtube', 1863),\n",
              " ('lose', 1861),\n",
              " ('worth', 1841),\n",
              " ('great', 1839),\n",
              " ('earn', 1833),\n",
              " ('test', 1833),\n",
              " ('god', 1827),\n",
              " ('states', 1826),\n",
              " ('against', 1819),\n",
              " ('win', 1814),\n",
              " ('mba', 1808),\n",
              " ('market', 1808),\n",
              " ('making', 1805),\n",
              " ('keep', 1803),\n",
              " ('hillary', 1801),\n",
              " ('compare', 1796),\n",
              " ('differences', 1794),\n",
              " ('answer', 1792),\n",
              " ('something', 1789),\n",
              " ('tips', 1787),\n",
              " ('java', 1783),\n",
              " ('apply', 1780),\n",
              " ('considered', 1780),\n",
              " ('around', 1778),\n",
              " ('myself', 1772),\n",
              " ('never', 1768),\n",
              " ('next', 1767),\n",
              " ('mechanical', 1761),\n",
              " ('8', 1759),\n",
              " ('always', 1757),\n",
              " ('month', 1754),\n",
              " ('another', 1747),\n",
              " ('united', 1747),\n",
              " ('course', 1739),\n",
              " ('jobs', 1738),\n",
              " ('increase', 1734),\n",
              " ('download', 1731),\n",
              " ('$', 1727),\n",
              " ('such', 1725),\n",
              " ('song', 1717),\n",
              " ('internet', 1716),\n",
              " ('parents', 1712),\n",
              " ('design', 1710),\n",
              " ('code', 1709),\n",
              " ('woman', 1698),\n",
              " ('common', 1692),\n",
              " ('kind', 1690),\n",
              " ('chinese', 1688),\n",
              " ('review', 1686),\n",
              " ('per', 1686),\n",
              " ('series', 1683),\n",
              " ('interesting', 1677),\n",
              " ('open', 1677),\n",
              " ('employees', 1670),\n",
              " ('development', 1669),\n",
              " ('degree', 1659),\n",
              " ('type', 1659),\n",
              " ('looking', 1657),\n",
              " ('score', 1655),\n",
              " ('living', 1654),\n",
              " ('show', 1652),\n",
              " ('management', 1648),\n",
              " ('months', 1646),\n",
              " ('travel', 1642),\n",
              " ('able', 1633),\n",
              " ('believe', 1622),\n",
              " ('program', 1620),\n",
              " ('well', 1603),\n",
              " ('light', 1602),\n",
              " ('bangalore', 1601),\n",
              " ('because', 1601),\n",
              " ('.?', 1593),\n",
              " ('law', 1589),\n",
              " ('family', 1584),\n",
              " ('pakistan', 1581),\n",
              " ('favorite', 1578),\n",
              " ('america', 1575),\n",
              " ('marketing', 1573),\n",
              " ('major', 1569),\n",
              " ('today', 1567),\n",
              " ('universities', 1563),\n",
              " ('actually', 1562),\n",
              " ('re', 1559),\n",
              " ('0', 1555),\n",
              " ('2017', 1553),\n",
              " ('space', 1550),\n",
              " ('call', 1545),\n",
              " ('cat', 1545),\n",
              " ('air', 1544),\n",
              " ('technology', 1542),\n",
              " ('based', 1540),\n",
              " ('whatsapp', 1535),\n",
              " ('%', 1533),\n",
              " ('idea', 1529),\n",
              " ('affect', 1529),\n",
              " ('build', 1519),\n",
              " ('current', 1514),\n",
              " ('popular', 1513),\n",
              " ('speed', 1512),\n",
              " ('self', 1511),\n",
              " ('problem', 1511),\n",
              " ('support', 1510),\n",
              " ('run', 1508),\n",
              " ('visa', 1506),\n",
              " ('choose', 1505),\n",
              " ('down', 1494),\n",
              " ('deal', 1491),\n",
              " ('games', 1491),\n",
              " ('rid', 1486),\n",
              " ('join', 1483),\n",
              " ('boyfriend', 1481),\n",
              " ('house', 1477),\n",
              " ('city', 1475),\n",
              " ('jee', 1474),\n",
              " ('mind', 1473),\n",
              " ('iit', 1468),\n",
              " ('site', 1466),\n",
              " ('both', 1465),\n",
              " ('services', 1460),\n",
              " ('exist', 1449),\n",
              " ('available', 1439),\n",
              " ('etc', 1438),\n",
              " ('civil', 1435),\n",
              " ('date', 1433),\n",
              " ('culture', 1432),\n",
              " ('normal', 1431),\n",
              " ('small', 1430),\n",
              " ('also', 1428),\n",
              " ('order', 1428),\n",
              " ('apple', 1426),\n",
              " ('product', 1426),\n",
              " ('apps', 1423),\n",
              " ('wrong', 1423),\n",
              " ('given', 1419),\n",
              " ('amazon', 1418),\n",
              " ('ms', 1414),\n",
              " ('places', 1412),\n",
              " ('songs', 1411),\n",
              " ('wear', 1407),\n",
              " ('project', 1406),\n",
              " ('value', 1394),\n",
              " ('international', 1393),\n",
              " ('main', 1391),\n",
              " ('differ', 1390),\n",
              " ('part', 1389),\n",
              " ('research', 1389),\n",
              " ('canada', 1389),\n",
              " ('uk', 1388),\n",
              " ('behind', 1388),\n",
              " ('post', 1388),\n",
              " (']', 1387),\n",
              " ('public', 1382),\n",
              " ('media', 1378),\n",
              " ('level', 1374),\n",
              " ('[', 1370),\n",
              " ('happened', 1370),\n",
              " ('^', 1362),\n",
              " ('education', 1357),\n",
              " ('email', 1357),\n",
              " ('cause', 1353),\n",
              " ('reason', 1353),\n",
              " ('less', 1347),\n",
              " ('sleep', 1339),\n",
              " ('startup', 1338),\n",
              " ('websites', 1336),\n",
              " ('benefits', 1331),\n",
              " ('these', 1330),\n",
              " ('list', 1329),\n",
              " ('instead', 1328),\n",
              " ('medical', 1327),\n",
              " ('die', 1316),\n",
              " ('child', 1306),\n",
              " ('physics', 1303),\n",
              " ('skills', 1301),\n",
              " ('times', 1300),\n",
              " ('called', 1298),\n",
              " ('form', 1295),\n",
              " ('visit', 1287),\n",
              " ('health', 1287),\n",
              " ('=', 1286),\n",
              " ('hate', 1283),\n",
              " ('worst', 1278),\n",
              " ('causes', 1276),\n",
              " ('didn', 1265),\n",
              " ('legal', 1259),\n",
              " ('control', 1259),\n",
              " ('police', 1255),\n",
              " ('face', 1254),\n",
              " ('products', 1243),\n",
              " ('mumbai', 1241),\n",
              " ('stay', 1239),\n",
              " ('terms', 1237),\n",
              " ('application', 1230),\n",
              " ('sites', 1228),\n",
              " ('facts', 1228),\n",
              " ('rate', 1222),\n",
              " ('field', 1221),\n",
              " ('story', 1216),\n",
              " ('sell', 1216),\n",
              " ('machine', 1215),\n",
              " ('seen', 1214),\n",
              " ('file', 1214),\n",
              " ('dog', 1212),\n",
              " ('500', 1212),\n",
              " ('humans', 1211),\n",
              " ('private', 1210),\n",
              " ('9', 1210),\n",
              " ('required', 1209),\n",
              " ('stock', 1208),\n",
              " ('notes', 1207),\n",
              " ('gate', 1202),\n",
              " ('modi', 1200),\n",
              " ('100', 1198),\n",
              " ('low', 1198),\n",
              " ('single', 1198),\n",
              " ('full', 1195),\n",
              " ('asked', 1195),\n",
              " ('biggest', 1192),\n",
              " ('point', 1192),\n",
              " ('writing', 1191),\n",
              " ('children', 1190),\n",
              " ('night', 1186),\n",
              " ('20', 1185),\n",
              " ('invest', 1185),\n",
              " ('indians', 1181),\n",
              " ('problems', 1180),\n",
              " ('move', 1178),\n",
              " ('rs', 1172),\n",
              " ('side', 1168),\n",
              " ('2015', 1167),\n",
              " ('anything', 1166),\n",
              " ('put', 1165),\n",
              " ('successful', 1165),\n",
              " ('remove', 1158),\n",
              " ('death', 1157),\n",
              " ('won', 1157),\n",
              " ('others', 1156),\n",
              " ('answers', 1155),\n",
              " ('theory', 1151),\n",
              " ('12', 1150),\n",
              " ('talk', 1147),\n",
              " ('ideas', 1147),\n",
              " ('compared', 1145),\n",
              " ('plan', 1139),\n",
              " ('marks', 1139),\n",
              " ('group', 1138),\n",
              " ('hours', 1132),\n",
              " ('advantages', 1132),\n",
              " ('000', 1131),\n",
              " ('similar', 1130),\n",
              " ('sentence', 1126),\n",
              " ('1000', 1125),\n",
              " ('tax', 1124),\n",
              " ('institute', 1123),\n",
              " ('add', 1123),\n",
              " ('again', 1122),\n",
              " ('effects', 1122),\n",
              " ('australia', 1120),\n",
              " ('famous', 1120),\n",
              " ('coaching', 1117),\n",
              " ('15', 1116),\n",
              " ('d', 1114),\n",
              " ('correct', 1111),\n",
              " ('solve', 1109),\n",
              " ('function', 1109),\n",
              " ('credit', 1107),\n",
              " ('center', 1104),\n",
              " ('known', 1102),\n",
              " ('lot', 1097),\n",
              " ('send', 1096),\n",
              " ('set', 1095),\n",
              " ('germany', 1094),\n",
              " ('south', 1092),\n",
              " ('guys', 1090),\n",
              " ('force', 1088),\n",
              " ('ex', 1085),\n",
              " ('training', 1081),\n",
              " ('offer', 1080),\n",
              " ('developer', 1079),\n",
              " ('star', 1077),\n",
              " ('left', 1077),\n",
              " ('term', 1077),\n",
              " ('videos', 1076),\n",
              " ('universe', 1075),\n",
              " ('foreign', 1074),\n",
              " ('daily', 1073),\n",
              " ('fall', 1072),\n",
              " ('information', 1072),\n",
              " ('studying', 1070),\n",
              " ('industry', 1070),\n",
              " ('oil', 1069),\n",
              " ('colleges', 1069),\n",
              " ('period', 1069),\n",
              " ('model', 1067),\n",
              " ('graduate', 1065),\n",
              " ('area', 1064),\n",
              " ('says', 1064),\n",
              " ('must', 1062),\n",
              " ('quality', 1060),\n",
              " ('general', 1060),\n",
              " ('python', 1059),\n",
              " ('size', 1057),\n",
              " ('near', 1053),\n",
              " ('drive', 1052),\n",
              " ('blood', 1043),\n",
              " ('n', 1043),\n",
              " ('majors', 1041),\n",
              " ('price', 1037),\n",
              " ('yourself', 1036),\n",
              " ('related', 1034),\n",
              " ('search', 1033),\n",
              " ('week', 1029),\n",
              " ('enough', 1028),\n",
              " ('words', 1028),\n",
              " ('cons', 1025),\n",
              " ('kill', 1024),\n",
              " ('marriage', 1022),\n",
              " ('fast', 1013),\n",
              " ('party', 1012),\n",
              " ('pros', 1011),\n",
              " ('found', 1009),\n",
              " ('courses', 1009),\n",
              " ('leave', 1006),\n",
              " ('often', 1006),\n",
              " ('follow', 1005),\n",
              " ('purpose', 1002),\n",
              " ('grow', 1000),\n",
              " ('russia', 999),\n",
              " ('male', 998),\n",
              " ('short', 998),\n",
              " ('started', 997),\n",
              " ('isn', 997),\n",
              " ('network', 995),\n",
              " ('fix', 992),\n",
              " ('advice', 990),\n",
              " ('store', 989),\n",
              " ('mass', 988),\n",
              " ('turn', 986),\n",
              " ('types', 986),\n",
              " ('married', 986),\n",
              " ('text', 982),\n",
              " ('brain', 981),\n",
              " ('password', 981),\n",
              " ('taking', 979),\n",
              " ('those', 977),\n",
              " ('female', 973),\n",
              " ('second', 970),\n",
              " ('team', 967),\n",
              " ('line', 966),\n",
              " ('page', 966),\n",
              " ('dark', 965),\n",
              " ('share', 962),\n",
              " ('numbers', 961),\n",
              " ('digital', 959),\n",
              " ('red', 959),\n",
              " ('effective', 959),\n",
              " ('three', 958),\n",
              " ('americans', 958),\n",
              " ('cell', 957),\n",
              " ('pc', 956),\n",
              " ('election', 952),\n",
              " ('office', 952),\n",
              " ('master', 950),\n",
              " ('view', 950),\n",
              " ('matter', 950),\n",
              " ('fat', 947),\n",
              " ('delete', 946),\n",
              " ('economy', 946),\n",
              " ('source', 944),\n",
              " ('security', 942),\n",
              " ('role', 940),\n",
              " ('ca', 939),\n",
              " ('easy', 938),\n",
              " ('“', 935),\n",
              " ('since', 935),\n",
              " ('few', 933),\n",
              " ('preparation', 932),\n",
              " ('happy', 929),\n",
              " ('options', 928),\n",
              " ('away', 928),\n",
              " ('said', 927),\n",
              " ('30', 924),\n",
              " ('north', 922),\n",
              " ('effect', 920),\n",
              " ('admission', 916),\n",
              " ('check', 916),\n",
              " ('chemical', 915),\n",
              " ('uber', 915),\n",
              " ('ios', 914),\n",
              " ('lost', 914),\n",
              " ('japanese', 913),\n",
              " ('electrical', 913),\n",
              " ('care', 913),\n",
              " ('profile', 911),\n",
              " ('wife', 911),\n",
              " ('understand', 909),\n",
              " ('dream', 909),\n",
              " ('difficult', 908),\n",
              " ('exams', 908),\n",
              " ('try', 907),\n",
              " ('religion', 906),\n",
              " ('paper', 906),\n",
              " ('investment', 906),\n",
              " ('convert', 904),\n",
              " ('alcohol', 904),\n",
              " ('past', 902),\n",
              " ('):', 902),\n",
              " ('develop', 901),\n",
              " ('letter', 901),\n",
              " ('hotel', 901),\n",
              " ('dogs', 900),\n",
              " ('beautiful', 899),\n",
              " ('exactly', 898),\n",
              " ('japan', 898),\n",
              " ('personal', 897),\n",
              " ('languages', 894),\n",
              " ('eating', 892),\n",
              " ('hyderabad', 889),\n",
              " ('topics', 889),\n",
              " ('vs', 889),\n",
              " ('calculate', 888),\n",
              " ('net', 888),\n",
              " ('explain', 885),\n",
              " ('british', 883),\n",
              " ('twitter', 879),\n",
              " ('green', 878),\n",
              " ('boy', 875),\n",
              " ('news', 873),\n",
              " ('political', 873),\n",
              " ('basic', 872),\n",
              " ('film', 871),\n",
              " ('drug', 870),\n",
              " ('transfer', 868),\n",
              " ('rank', 865),\n",
              " ('fight', 865),\n",
              " ('california', 864),\n",
              " ('army', 863),\n",
              " ('national', 862),\n",
              " ('please', 862),\n",
              " ('let', 860),\n",
              " ('pune', 859),\n",
              " ('porn', 858),\n",
              " ('contact', 857),\n",
              " ('pro', 855),\n",
              " ('note', 852),\n",
              " ('scope', 852),\n",
              " ('once', 850),\n",
              " ('paid', 850),\n",
              " ('address', 848),\n",
              " ('avoid', 847),\n",
              " ('smart', 845),\n",
              " ('gain', 844),\n",
              " ('europe', 843),\n",
              " (\"'?\", 840),\n",
              " ('wants', 838),\n",
              " ('engine', 837),\n",
              " ('phd', 836),\n",
              " ('reasons', 836),\n",
              " ('bollywood', 834),\n",
              " ('income', 832),\n",
              " ('obama', 832),\n",
              " ('currently', 830),\n",
              " ('samsung', 829),\n",
              " ('season', 829),\n",
              " ('hindi', 828),\n",
              " ('officer', 826),\n",
              " ('everyone', 825),\n",
              " ('reading', 825),\n",
              " ('military', 819),\n",
              " ('reduce', 819),\n",
              " ('11', 818),\n",
              " ('chances', 817),\n",
              " ('meet', 815),\n",
              " ('ias', 815),\n",
              " ('users', 813),\n",
              " ('everything', 813),\n",
              " ('option', 813),\n",
              " ('knowledge', 811),\n",
              " ('overcome', 810),\n",
              " ('across', 810),\n",
              " ('solar', 809),\n",
              " ('else', 809),\n",
              " ('internship', 806),\n",
              " ('50', 806),\n",
              " ('message', 805),\n",
              " ('muslim', 805),\n",
              " ('charge', 804),\n",
              " ('gay', 804),\n",
              " ('sim', 803),\n",
              " ('moon', 802),\n",
              " ('yes', 800),\n",
              " ('microsoft', 800),\n",
              " ('due', 799),\n",
              " ('sound', 799),\n",
              " ('photos', 797),\n",
              " ('disadvantages', 797),\n",
              " ('pass', 797),\n",
              " ('balance', 796),\n",
              " ('faster', 793),\n",
              " ('financial', 791),\n",
              " ('muslims', 790),\n",
              " ('pregnant', 789),\n",
              " ('taken', 788),\n",
              " ('screen', 784),\n",
              " ('break', 783),\n",
              " ('hack', 783),\n",
              " ('healthy', 781),\n",
              " ('pain', 780),\n",
              " ('singapore', 780),\n",
              " ('animals', 780),\n",
              " ('messages', 780),\n",
              " ('16', 780),\n",
              " ('systems', 780),\n",
              " ('natural', 778),\n",
              " ('skin', 776),\n",
              " ('amount', 775),\n",
              " ('color', 774),\n",
              " ('board', 773),\n",
              " ('special', 773),\n",
              " ('interested', 772),\n",
              " ('case', 771),\n",
              " ('chance', 770),\n",
              " ('sun', 770),\n",
              " ('names', 770),\n",
              " ('hand', 768),\n",
              " ('height', 767),\n",
              " ('professional', 766),\n",
              " ('drink', 766),\n",
              " ('passport', 765),\n",
              " ('structure', 765),\n",
              " ('french', 764),\n",
              " ('created', 764),\n",
              " ('percentage', 762),\n",
              " ('german', 762),\n",
              " ('useful', 760),\n",
              " ('already', 759),\n",
              " ('mother', 758),\n",
              " ('linux', 755),\n",
              " ('modern', 755),\n",
              " ('middle', 755),\n",
              " ('crush', 755),\n",
              " ('user', 755),\n",
              " ('dating', 754),\n",
              " ('likes', 754),\n",
              " ('blue', 752),\n",
              " ('battery', 750),\n",
              " ('access', 749),\n",
              " ('starting', 745),\n",
              " ('train', 745),\n",
              " ('interest', 745),\n",
              " ('presidential', 744),\n",
              " ('written', 743),\n",
              " ('coming', 743),\n",
              " ('install', 742),\n",
              " ('camera', 741),\n",
              " ('negative', 741),\n",
              " ('recover', 741),\n",
              " ('provide', 740),\n",
              " ('least', 740),\n",
              " ('studies', 739),\n",
              " ('thinking', 739),\n",
              " ('cold', 738),\n",
              " ('football', 737),\n",
              " ('rich', 736),\n",
              " ('solution', 736),\n",
              " ('prime', 736),\n",
              " ('vote', 735),\n",
              " ('expect', 735),\n",
              " ('mac', 733),\n",
              " ('following', 733),\n",
              " ('buying', 732),\n",
              " ('spend', 731),\n",
              " ('gift', 731),\n",
              " ('running', 730),\n",
              " ('jio', 730),\n",
              " ('resources', 730),\n",
              " ('brand', 728),\n",
              " ('cs', 727),\n",
              " ('\\\\', 726),\n",
              " ('pressure', 725),\n",
              " ('changed', 724),\n",
              " ('feeling', 724),\n",
              " ('character', 724),\n",
              " ('gmail', 722),\n",
              " ('allowed', 720),\n",
              " ('marry', 717),\n",
              " ('shows', 716),\n",
              " ('within', 715),\n",
              " ('islam', 714),\n",
              " ('society', 714),\n",
              " ('speak', 713),\n",
              " ('snapchat', 713),\n",
              " ('eyes', 713),\n",
              " ('laws', 712),\n",
              " ('yet', 711),\n",
              " ('impact', 711),\n",
              " ('fake', 709),\n",
              " ('schools', 709),\n",
              " ('final', 709),\n",
              " ('bill', 709),\n",
              " ('save', 706),\n",
              " ('likely', 704),\n",
              " ('nuclear', 704),\n",
              " ('though', 703),\n",
              " ('capital', 702),\n",
              " ('{', 701),\n",
              " ('determine', 701),\n",
              " ('neet', 699),\n",
              " ('chemistry', 699),\n",
              " ('doctor', 698),\n",
              " ('cut', 697),\n",
              " ('picture', 697),\n",
              " ('applications', 696),\n",
              " ('husband', 692),\n",
              " ('manager', 692),\n",
              " ('young', 691),\n",
              " ('kids', 691),\n",
              " ('prefer', 691),\n",
              " ('stories', 690),\n",
              " ('views', 690),\n",
              " ('g', 689),\n",
              " ('father', 689),\n",
              " ('device', 689),\n",
              " ('iq', 688),\n",
              " ('gold', 688),\n",
              " ('personality', 687),\n",
              " ('galaxy', 685),\n",
              " ('inside', 685),\n",
              " ('projects', 684),\n",
              " ('r', 683),\n",
              " ('18', 683),\n",
              " ('blog', 682),\n",
              " ('strategy', 681),\n",
              " ('greatest', 681),\n",
              " ('cse', 680),\n",
              " ('illegal', 680),\n",
              " ('currency', 679),\n",
              " ('abroad', 678),\n",
              " ('technical', 677),\n",
              " ('crack', 676),\n",
              " ('pursue', 675),\n",
              " ('art', 675),\n",
              " ('alone', 674),\n",
              " ('recruit', 674),\n",
              " ('works', 674),\n",
              " ('example', 673),\n",
              " ('growth', 673),\n",
              " ('memory', 673),\n",
              " ('higher', 673),\n",
              " ('consider', 672),\n",
              " ('dead', 671),\n",
              " ('depression', 670),\n",
              " ('insurance', 669),\n",
              " ('head', 669),\n",
              " ('core', 666),\n",
              " ('wifi', 666),\n",
              " ...]"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_tokens = list()\n",
        "for a in data_tok:\n",
        "    all_tokens.extend(a)\n",
        "dict = nltk.FreqDist(all_tokens)\n",
        "len_dict = len(dict)\n",
        "print(f'vocabulary size: {len_dict}')\n",
        "top10 = dict.most_common(80000)\n",
        "top10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1SM3sn1zf1b"
      },
      "source": [
        "###Задание 3: Подсчитайте количество разных слов до и после лемматизации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Q88BIteDzpWR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before lemmatization: 7131337, after lemmatization: 80304\n"
          ]
        }
      ],
      "source": [
        "count_before_lemm = len(all_tokens)\n",
        "after_lemm = set()\n",
        "for a in all_tokens:\n",
        "    after_lemm.add(lemmatizer.lemmatize(a))\n",
        "count_after_lemm = len(after_lemm)\n",
        "print(f'Before lemmatization: {count_before_lemm}, after lemmatization: {count_after_lemm}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxKa8yUUzqNN"
      },
      "source": [
        "###Задание 4: Подсчитайте количество разных слов до и после стемминга"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "x91DX51qzszR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before stemming: 7131337, after stemming: 67026\n"
          ]
        }
      ],
      "source": [
        "count_before_stemm = len(all_tokens)\n",
        "after_stemm = set()\n",
        "for a in all_tokens:\n",
        "    after_stemm.add(ps.stem(a))\n",
        "count_after_stemm = len(after_stemm)\n",
        "print(f'Before stemming: {count_before_stemm}, after stemming: {count_after_stemm}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXA7Fe_izuqh"
      },
      "source": [
        "###Задание 5: Подсчитайте количество разных слов\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "BGgmHzUAzwqO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count stem after lem: 66835, count lem after stem: 66818\n"
          ]
        }
      ],
      "source": [
        "stem_after_lemm = set()\n",
        "for a in after_lemm:\n",
        "    stem_after_lemm.add(ps.stem(a))\n",
        "count_stem_after_lem = len(stem_after_lemm)\n",
        "\n",
        "lemm_after_stem = set()\n",
        "for a in after_stemm:\n",
        "    lemm_after_stem.add(lemmatizer.lemmatize(a))\n",
        "count_lemm_after_stem = len(lemm_after_stem)\n",
        "\n",
        "print(f'Count stem after lem: {count_stem_after_lem}, count lem after stem: {count_lemm_after_stem}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At9iloRCVShn"
      },
      "source": [
        "REGEXP\n",
        "\n",
        "https://www.programiz.com/python-programming/regex \n",
        "\n",
        "https://docs.python.org/3/howto/regex.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "521aLisyVUg_",
        "outputId": "fd21b30e-aadf-47eb-e776-ba59ff427d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search unsuccessful.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "pattern = 'a*s'\n",
        "test_string = 'abyss'\n",
        "result = re.match(pattern, test_string)\n",
        "\n",
        "if result:\n",
        "  print(\"Search successful.\")\n",
        "else:\n",
        "  print(\"Search unsuccessful.\")\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MATCH: str: hackerrank bla bla bla  contains the word hackerrank\n",
            "MATCH: str: not as good as hackerrank contains the word hackerrank\n",
            "MISSS: str: does not contains hacker_rank doesn't contain the word hackerrank\n"
          ]
        }
      ],
      "source": [
        "###Задание 6: \n",
        "###https://www.hackerrank.com/challenges/matching-specific-string/problem?isFullScreen=true \n",
        "def check_hackerrank(t: str):\n",
        "    p = re.compile('.*?hackerrank.*?')\n",
        "    if p.match(t):\n",
        "        print(f'MATCH: str: {t} contains the word hackerrank')\n",
        "        return True\n",
        "    else:\n",
        "        print(f'MISSS: str: {t} doesn\\'t contain the word hackerrank')\n",
        "        return False\n",
        "\n",
        "assert check_hackerrank('hackerrank bla bla bla ') #start\n",
        "assert check_hackerrank('not as good as hackerrank') # end\n",
        "assert not check_hackerrank('does not contains hacker_rank') # missed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "###Задание 7: \n",
        "###https://www.hackerrank.com/challenges/matching-whitespace-non-whitespace-character/problem?isFullScreen=true\n",
        "### implement pattern XX_XX_XX\n",
        "\n",
        "def check_pattern(t: str):\n",
        "    tt = re.compile('^(..)\\s(..)\\s(..)$')\n",
        "    return tt.match(t)\n",
        "\n",
        "assert check_pattern('10 11 12')\n",
        "assert check_pattern('df 12 f5')\n",
        "assert not check_pattern(' . df 23 gd ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "###Задание 8: \n",
        "###https://www.hackerrank.com/challenges/matching-start-end/problem?isFullScreen=true\n",
        "def check_pattern_task8(t: str):\n",
        "    tt = re.compile('^(\\d)(\\D{6})\\.$')\n",
        "    return tt.match(t)\n",
        "\n",
        "assert check_pattern_task8('9mmmmmm.')\n",
        "assert not check_pattern_task8(' 9mmmmmm.')\n",
        "assert not check_pattern_task8('9mmmmmmm.')\n",
        "assert not check_pattern_task8('9mmmmmmm')\n",
        "assert not check_pattern_task8(' 9mmmmm. ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "###Задание 9: \n",
        "###https://www.hackerrank.com/challenges/matching-word-boundaries/problem?isFullScreen=true\n",
        "###You have a test String .\n",
        "##Your task is to write a regex which will match word starting with vowel (a,e,i,o, u, A, E, I , O or U).\n",
        "##The matched word can be of any length. The matched word should consist of letters (lowercase and uppercase both) only.\n",
        "##The matched word must start and end with a word boundary.\n",
        "\n",
        "def check_pattern_task9(t: str):\n",
        "    tt = re.compile('^[aeiouAEIOU]\\S+$')\n",
        "    return tt.match(t)\n",
        "\n",
        "assert check_pattern_task9('aLFLFLFLF')\n",
        "assert not check_pattern_task9('bLFLFLFLF')\n",
        "assert not check_pattern_task9('bLFLF LFLF')\n",
        "assert not check_pattern_task9('9bLFLF LFLF')\n",
        "assert not check_pattern_task9(' 9bLFLF LFLF')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Csv2YN2IRXJB"
      },
      "source": [
        "Bag Of Words (BOW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8YWG3JhSFeZ",
        "outputId": "325b4fa5-7d56-4993-b4d0-1aae78bad94e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['welcome', 'to', 'great', 'learning', ',', 'now', 'start', 'learning']\n",
            "['learning', 'is', 'a', 'good', 'practice']\n",
            "filtered vocabulary: ['welcome', 'great', 'learning', 'now', 'start', 'good', 'practice']\n",
            "[1, 1, 2, 1, 1, 0, 0]\n",
            "[0, 0, 1, 0, 0, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "def vectorize(tokens):\n",
        "    ''' This function takes list of words in a sentence as input \n",
        "    and returns a vector of size of filtered_vocab.It puts 0 if the \n",
        "    word is not present in tokens and count of token if present.'''\n",
        "    vector=[]\n",
        "    for w in filtered_vocab:\n",
        "        vector.append(tokens.count(w))\n",
        "    return vector\n",
        "def unique(sequence):\n",
        "    '''This functions returns a list in which the order remains \n",
        "    same and no item repeats.Using the set() function does not \n",
        "    preserve the original ordering,so i didnt use that instead'''\n",
        "    seen = set()\n",
        "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
        "\n",
        "#create a list of stopwords.You can import stopwords from nltk too\n",
        "stopwords=[\"to\",\"is\",\"a\"]\n",
        "\n",
        "#list of special characters.You can use regular expressions too\n",
        "special_char=[\",\",\":\",\" \",\";\",\".\",\"?\"]\n",
        "\n",
        "#Write the sentences in the corpus,in our case, just two \n",
        "string1=\"Welcome to Great Learning , Now start learning\"\n",
        "string2=\"Learning is a good practice\"\n",
        "\n",
        "#convert them to lower case\n",
        "string1=string1.lower()\n",
        "string2=string2.lower()\n",
        "\n",
        "#split the sentences into tokens\n",
        "tokens1=string1.split()\n",
        "tokens2=string2.split()\n",
        "print(tokens1)\n",
        "print(tokens2)\n",
        "\n",
        "#create a vocabulary list\n",
        "vocab=unique(tokens1+tokens2)\n",
        "# print(vocab)\n",
        "\n",
        "#filter the vocabulary list\n",
        "filtered_vocab=[]\n",
        "for w in vocab: \n",
        "    if w not in stopwords and w not in special_char: \n",
        "        filtered_vocab.append(w)\n",
        "print(f'filtered vocabulary: {filtered_vocab}')\n",
        "\n",
        "#convert sentences into vectords\n",
        "vector1=vectorize(tokens1)\n",
        "print(vector1)\n",
        "vector2=vectorize(tokens2)\n",
        "print(vector2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOZ1qx05Q46b"
      },
      "source": [
        "Задание 10: Реализовать Bag of words на data_tok (можно на NLTK, можно без)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "Tew2nQN4OCiW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most similar sentences with score: 0.7559289460184544 are: \n",
            "What is your review of osquery?\n",
            "\n",
            "What is your review of iPad Mini 2?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "###https://www.geeksforgeeks.org/bag-of-words-bow-model-in-nlp/\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "X = []\n",
        "\n",
        "t = 0\n",
        "vocabulary = top10\n",
        "for data_loc in data_tok:\n",
        "    if t==50:\n",
        "        break\n",
        "    t+=1\n",
        "    vector = []\n",
        "    for word_ in vocabulary:\n",
        "        word = word_[0]\n",
        "        if word in data_loc:\n",
        "            vector.append(data_loc.count(word))\n",
        "        else:\n",
        "            vector.append(0)\n",
        "    X.append(vector)\n",
        "X = np.asarray(X)\n",
        "\n",
        "# for a in range(50):\n",
        "#     print(f'sentence: {data[a]}')\n",
        "\n",
        "index1 = 0\n",
        "index2 = 0  \n",
        "max_value = 0 \n",
        "\n",
        "for a in range(50):\n",
        "    for b in range(a+1, 50):\n",
        "        cur_res  = dot(X[a], X[b])/(norm(X[a])*norm(X[b]))\n",
        "        if cur_res > max_value:\n",
        "            max_value = cur_res\n",
        "            index1 = a\n",
        "            index2 = b\n",
        "\n",
        "print(f'The most similar sentences with score: {max_value} are: ' )\n",
        "print(f'{data[index1]}')\n",
        "print(f'{data[index2]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "# text=[\"kolkata big city india trade\",\"mumbai financial capital india\",\"delhi capital india\",\"kolkata capital colonial times\",\n",
        "#      \"bangalore tech hub india software\",\"mumbai hub trade commerce stock exchange\",\"kolkata victoria memorial\",\"delhi india gate\",\n",
        "#       \"mumbai gate way india trade business\",\"delhi red fort india\",\"kolkata metro oldest india\",\n",
        "#       \"delhi metro largest metro network india\"]\n",
        "counter = 0\n",
        "text_list = list()\n",
        "for a in data_tok:\n",
        "    counter+=1\n",
        "    if counter == 50:\n",
        "        break;\n",
        "    t = ' '.join(a)\n",
        "    text_list.append(t)\n",
        "text = text_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 37)\t1\n",
            "  (0, 100)\t1\n",
            "  (0, 26)\t1\n",
            "  (0, 260)\t2\n",
            "  (0, 159)\t1\n",
            "  (0, 81)\t1\n",
            "  (0, 79)\t1\n",
            "  (0, 228)\t1\n",
            "  (0, 206)\t1\n",
            "  (0, 129)\t1\n",
            "  (0, 186)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 109)\t1\n",
            "  (0, 25)\t1\n",
            "  (1, 252)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 214)\t1\n",
            "  (1, 247)\t1\n",
            "  (1, 231)\t1\n",
            "  (1, 178)\t1\n",
            "  (1, 87)\t1\n",
            "  (1, 92)\t1\n",
            "  (1, 6)\t1\n",
            "  (2, 256)\t2\n",
            "  (2, 251)\t1\n",
            "  :\t:\n",
            "  (46, 100)\t1\n",
            "  (46, 9)\t1\n",
            "  (46, 19)\t1\n",
            "  (46, 114)\t1\n",
            "  (46, 202)\t1\n",
            "  (46, 220)\t1\n",
            "  (46, 126)\t1\n",
            "  (46, 105)\t1\n",
            "  (46, 201)\t1\n",
            "  (47, 14)\t1\n",
            "  (47, 256)\t1\n",
            "  (47, 226)\t1\n",
            "  (47, 122)\t1\n",
            "  (47, 35)\t1\n",
            "  (47, 232)\t1\n",
            "  (47, 50)\t1\n",
            "  (47, 22)\t1\n",
            "  (48, 231)\t1\n",
            "  (48, 257)\t1\n",
            "  (48, 63)\t1\n",
            "  (48, 93)\t1\n",
            "  (48, 101)\t1\n",
            "  (48, 244)\t1\n",
            "  (48, 33)\t1\n",
            "  (48, 189)\t1\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "#using the count vectorizer\n",
        "count = CountVectorizer()\n",
        "word_count=count.fit_transform(text)\n",
        "print(word_count)\n",
        "print(word_count.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/max/miniforge3/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(word_count)\n",
        "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=count.get_feature_names(),columns=[\"idf_weights\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idf_weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>2.021651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is</th>\n",
              "      <td>2.139434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>how</th>\n",
              "      <td>2.139434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>what</th>\n",
              "      <td>2.203973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>can</th>\n",
              "      <td>2.427116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal</th>\n",
              "      <td>4.218876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goldman</th>\n",
              "      <td>4.218876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>graphic</th>\n",
              "      <td>4.218876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>martin</th>\n",
              "      <td>4.218876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zotac</th>\n",
              "      <td>4.218876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>269 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         idf_weights\n",
              "the         2.021651\n",
              "is          2.139434\n",
              "how         2.139434\n",
              "what        2.203973\n",
              "can         2.427116\n",
              "...              ...\n",
              "goal        4.218876\n",
              "goldman     4.218876\n",
              "graphic     4.218876\n",
              "martin      4.218876\n",
              "zotac       4.218876\n",
              "\n",
              "[269 rows x 1 columns]"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#inverse document frequency\n",
        "df_idf.sort_values(by=['idf_weights'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/max/miniforge3/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fast</th>\n",
              "      <td>0.375854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>food</th>\n",
              "      <td>0.375854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>addiction</th>\n",
              "      <td>0.375854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>some</th>\n",
              "      <td>0.375854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ways</th>\n",
              "      <td>0.375854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>from</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>george</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>get</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>girls</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zotac</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>269 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              tfidf\n",
              "fast       0.375854\n",
              "food       0.375854\n",
              "addiction  0.375854\n",
              "some       0.375854\n",
              "ways       0.375854\n",
              "...             ...\n",
              "from       0.000000\n",
              "george     0.000000\n",
              "get        0.000000\n",
              "girls      0.000000\n",
              "zotac      0.000000\n",
              "\n",
              "[269 rows x 1 columns]"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#tfidf\n",
        "tf_idf_vector=tfidf_transformer.transform(word_count)\n",
        "feature_names = count.get_feature_names()\n",
        "first_document_vector=tf_idf_vector[1]\n",
        "df_tfifd= pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
        "df_tfifd.sort_values(by=[\"tfidf\"],ascending=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "fa0bc865107c7062c66623b84ed7848967abd0ba5cbabe70080959ae0fa18d9a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
