{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 4\n",
    "* Сравнить LSTM, RNN и GRU на задаче предсказания части речи (качество предсказания, скорость обучения, время инференса модели)\n",
    "* *к первой задаче добавить bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSeq(Dataset):\n",
    "    def __init__(self, data_dir, train_lang='en'):\n",
    "\t#open file\n",
    "        with open(data_dir + train_lang + '.train', 'r') as f:\n",
    "            train = f.read().split('\\n\\n')\n",
    "\n",
    "        # delete extra tag markup\n",
    "        train = [x for x in train if not '_ ' in x]\n",
    "\t    #init vocabs of tokens for encoding { token:  id}\n",
    "        self.target_vocab = {} # {p: 1, a: 2, r: 3, pu: 4}\n",
    "        self.word_vocab = {} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n",
    "        self.char_vocab = {} # {c: 1, a: 2, t: 3, ' ': 4, s: 5}\n",
    "\t    \n",
    "        # Cat sat on mat. -> [1, 2, 3, 4, 5]\n",
    "        # p    a  r  p pu -> [1, 2, 3, 1, 4]\n",
    "        # chars  -> [1, 2, 3, 4, 5, 2, 3, 4]\n",
    "\n",
    "\t    #init encoded sequences lists (processed data)\n",
    "        self.encoded_sequences = []\n",
    "        self.encoded_targets = []\n",
    "        self.encoded_char_sequences = []\n",
    "        # n=1 because first value is padding\n",
    "        n_word = 1\n",
    "        n_target = 1\n",
    "        n_char = 1\n",
    "        for line in train:\n",
    "            sequence = []\n",
    "            target = []\n",
    "            chars = []\n",
    "            for item in line.split('\\n'):\n",
    "                if item != '':\n",
    "                    word, label = item.split(' ')\n",
    "\n",
    "                    if self.word_vocab.get(word) is None:\n",
    "                        self.word_vocab[word] = n_word\n",
    "                        n_word += 1\n",
    "                    if self.target_vocab.get(label) is None:\n",
    "                        self.target_vocab[label] = n_target\n",
    "                        n_target += 1\n",
    "                    for char in word:\n",
    "                        if self.char_vocab.get(char) is None:\n",
    "                            self.char_vocab[char] = n_char\n",
    "                            n_char += 1\n",
    "                    sequence.append(self.word_vocab[word])\n",
    "                    target.append(self.target_vocab[label])\n",
    "                    chars.append([self.char_vocab[char] for char in word])\n",
    "            self.encoded_sequences.append(sequence)\n",
    "            self.encoded_targets.append(target)\n",
    "            self.encoded_char_sequences.append(chars)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n",
    "            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n",
    "            'target': self.encoded_targets[index], #  (1)\n",
    "        }\n",
    "\n",
    "dataset = DatasetSeq('')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    data = []\n",
    "    target = []\n",
    "    for item in batch:\n",
    "        data.append(torch.as_tensor(item['data']))\n",
    "        target.append(torch.as_tensor(item['target']))\n",
    "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    target = pad_sequence(target, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {'data': data, 'target': target}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNNPredictorV2(nn.Module):\n",
    "    # ну я тут добавил параметр, которым будет задаваться класс, модель с которым нам нужно создать\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes, cl):\n",
    "        super().__init__()\n",
    "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
    "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        # соответственно здесь - инициируется как раз объект этого класса, то есть модель в каждом случае  будет разная\n",
    "        self.rnn = cl(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb = self.word_emb(x) # B x T x Emb_dim\n",
    "        hidden, _ = self.rnn(emb) # B x T x Hid, B x 1 x Hid\n",
    "        pred = self.clf(self.do(hidden)) # B x T x N_classes\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper params\n",
    "vocab_size = len(dataset.word_vocab) + 1\n",
    "n_classes = len(dataset.target_vocab) + 1\n",
    "n_chars = len(dataset.char_vocab) + 1\n",
    "#TODO try to use other model parameters\n",
    "emb_dim = 128\n",
    "hidden = 128\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь я формирую три объекта модели и соответсвующего оптимизатора\n",
    "model_rnn = RNNPredictorV2(vocab_size, emb_dim, hidden, n_classes, nn.RNN).to(device)\n",
    "model_rnn.train()\n",
    "optim_rnn = torch.optim.Adam(model_rnn.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "model_lstm = RNNPredictorV2(vocab_size, emb_dim, hidden, n_classes, nn.LSTM).to(device)\n",
    "model_lstm.train()\n",
    "optim_lstm = torch.optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "model_gru = RNNPredictorV2(vocab_size, emb_dim, hidden, n_classes, nn.GRU).to(device)\n",
    "model_gru.train()\n",
    "optim_gru = torch.optim.Adam(model_gru.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch_stats_df = pd.DataFrame(columns=['Epoch','RNN', 'LSTM', 'GRU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size, shuffle=False, collate_fn=collate_fn, drop_last = True)\n",
    "print(len(dataloader))\n",
    "test_dataset = list()\n",
    "if exists('learning_stats.pickle'):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i>200:\n",
    "            test_dataset.append((i,batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn epoch:0| rnn: 5.376127004623413, lstm epoch: 11.591525077819824, gru: 10.183023929595947\n",
      "rnn epoch:1| rnn: 5.603142261505127, lstm epoch: 11.50241494178772, gru: 10.002900123596191\n",
      "rnn epoch:2| rnn: 5.598433971405029, lstm epoch: 11.477622985839844, gru: 10.011725902557373\n",
      "rnn epoch:3| rnn: 5.538758039474487, lstm epoch: 11.525661945343018, gru: 10.049337148666382\n",
      "rnn epoch:4| rnn: 5.6333417892456055, lstm epoch: 11.656707048416138, gru: 10.13768196105957\n",
      "rnn epoch:5| rnn: 5.69238805770874, lstm epoch: 11.673913955688477, gru: 10.19636607170105\n",
      "rnn epoch:6| rnn: 5.726492881774902, lstm epoch: 11.643841743469238, gru: 10.178048849105835\n",
      "rnn epoch:7| rnn: 5.6503260135650635, lstm epoch: 11.667803764343262, gru: 10.209052801132202\n",
      "rnn epoch:8| rnn: 5.667370080947876, lstm epoch: 11.696340084075928, gru: 10.227772235870361\n",
      "rnn epoch:9| rnn: 5.741461992263794, lstm epoch: 11.692317247390747, gru: 10.181402921676636\n",
      "here is dataframe with epoch epochs statistics\n"
     ]
    }
   ],
   "source": [
    "# служебный класс для прогона \"эпохи\"\n",
    "def process_epoch(model: nn.Module, optimizer: torch.optim.Optimizer):\n",
    "    time_before = time.time()\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i <= 200:\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(batch['data'].to(device))\n",
    "            loss = loss_func(predict.view(-1, n_classes),\n",
    "                             batch['target'].to(device).view(-1),\n",
    "                           )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        elif epoch==0:\n",
    "            test_dataset.append((i,batch)) # оставляю кусок датасета для замера времени инференса и подсчета качества каждой модели.  батчи [201-212] буду использовать для теста\n",
    "    time_after = time.time()\n",
    "    return time_after-time_before\n",
    "\n",
    "if not exists('learning_stats.pickle'):\n",
    "# обучающий цикл. он будет один, за одну эпоху обучаем все три модели. продолжительность эпохи длякаджой модели записываем в датафрейм\n",
    "    for epoch in range(n_epochs):\n",
    "        ### rnn\n",
    "        rnn_epoch_duration = process_epoch(model_rnn, optim_rnn)\n",
    "        lstm_epoch_duration = process_epoch(model_lstm, optim_lstm)\n",
    "        gru_epoch_duration = process_epoch(model_gru, optim_gru)\n",
    "        print(f'rnn epoch:{epoch}| rnn: {rnn_epoch_duration}, lstm epoch: {lstm_epoch_duration}, gru: {gru_epoch_duration}')\n",
    "        epoch_stats_df = epoch_stats_df.append({'Epoch': epoch, 'RNN':rnn_epoch_duration, 'LSTM':lstm_epoch_duration, 'GRU':gru_epoch_duration},ignore_index=True)\n",
    "        torch.save(model_rnn, 'my_rnn_model.pickle')\n",
    "        torch.save(model_lstm, 'my_lstm_model.pickle')\n",
    "        torch.save(model_gru, 'my_gru_model.pickle')\n",
    "\n",
    "        epoch_stats_df.to_pickle('learning_stats.pickle')\n",
    "else:\n",
    "    epoch_stats_df = pd.read_pickle('learning_stats.pickle')\n",
    "    model_rnn = torch.load('my_rnn_model.pickle')\n",
    "    model_lstm = torch.load('my_lstm_model.pickle')\n",
    "    model_gru = torch.load('my_gru_model.pickle')\n",
    "    \n",
    "print('here is dataframe with epoch epochs statistics')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>RNN</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.376127</td>\n",
       "      <td>11.591525</td>\n",
       "      <td>10.183024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.603142</td>\n",
       "      <td>11.502415</td>\n",
       "      <td>10.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.598434</td>\n",
       "      <td>11.477623</td>\n",
       "      <td>10.011726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.538758</td>\n",
       "      <td>11.525662</td>\n",
       "      <td>10.049337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.633342</td>\n",
       "      <td>11.656707</td>\n",
       "      <td>10.137682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.692388</td>\n",
       "      <td>11.673914</td>\n",
       "      <td>10.196366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.726493</td>\n",
       "      <td>11.643842</td>\n",
       "      <td>10.178049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.650326</td>\n",
       "      <td>11.667804</td>\n",
       "      <td>10.209053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.667370</td>\n",
       "      <td>11.696340</td>\n",
       "      <td>10.227772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.741462</td>\n",
       "      <td>11.692317</td>\n",
       "      <td>10.181403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch       RNN       LSTM        GRU\n",
       "0    0.0  5.376127  11.591525  10.183024\n",
       "1    1.0  5.603142  11.502415  10.002900\n",
       "2    2.0  5.598434  11.477623  10.011726\n",
       "3    3.0  5.538758  11.525662  10.049337\n",
       "4    4.0  5.633342  11.656707  10.137682\n",
       "5    5.0  5.692388  11.673914  10.196366\n",
       "6    6.0  5.726493  11.643842  10.178049\n",
       "7    7.0  5.650326  11.667804  10.209053\n",
       "8    8.0  5.667370  11.696340  10.227772\n",
       "9    9.0  5.741462  11.692317  10.181403"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Статистика времени обучения'}, xlabel='Epoch'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_stats_df_with_index = epoch_stats_df.set_index('Epoch')\n",
    "epoch_stats_df_with_index.plot(title = 'Статистика времени обучения', kind='bar' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = nn.L1Loss()\n",
    "\n",
    "def measure_inference_time(model: nn.Module, test_dataset: list):\n",
    "    result = np.zeros(len(test_dataset))\n",
    "    result_r2 = np.zeros(len(test_dataset))\n",
    "    model.eval()\n",
    "    numpy_index = 0\n",
    "    for i, batch in test_dataset:\n",
    "        time_bef = time.time()\n",
    "        cur_res = model(batch['data'].to(device))\n",
    "        exp_res = batch['target']\n",
    "        cur_res = torch.argmax(cur_res, dim=2)\n",
    "        r2 = r2_score(exp_res, cur_res)\n",
    "        result_r2[numpy_index] = r2\n",
    "        time_aft = time.time()\n",
    "        time_diff = time_aft - time_bef\n",
    "        result[numpy_index] = time_diff\n",
    "        numpy_index+=1\n",
    "    return np.average(result), np.average(result_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is some statistics of model's inference time: \n",
      "rnn: 0.009104873194839016\n",
      "lstm: 0.025652191855690697\n",
      "gru: 0.02012793223063151\n",
      "Here is some statistic about quality of difference models (comparing by r2_score):\n",
      "rnn r2: 0.7834413924168729\n",
      "lstm_r2: 0.83373787557998\n",
      "gru_r2: 0.601522692628728\n"
     ]
    }
   ],
   "source": [
    "rnn_res = measure_inference_time(model_rnn, test_dataset)\n",
    "inference_rnn = rnn_res[0]\n",
    "r2_rnn = rnn_res[1]\n",
    "lstm_res = measure_inference_time(model_lstm, test_dataset)\n",
    "inference_lstm = lstm_res[0]\n",
    "r2_lstm = lstm_res[1]\n",
    "gru_res = measure_inference_time(model_gru, test_dataset)\n",
    "inference_gru = gru_res[0]\n",
    "r2_gru = gru_res[1]\n",
    "\n",
    "print('Here is some statistics of model\\'s inference time: ')\n",
    "print(f'rnn: {inference_rnn}')\n",
    "print(f'lstm: {inference_lstm}')\n",
    "print(f'gru: {inference_gru}')\n",
    "\n",
    "print('Here is some statistic about quality of difference models (comparing by r2_score):')\n",
    "print(f'rnn r2: {r2_rnn}')\n",
    "print(f'lstm_r2: {r2_lstm}')\n",
    "print(f'gru_r2: {r2_gru}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa0bc865107c7062c66623b84ed7848967abd0ba5cbabe70080959ae0fa18d9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
